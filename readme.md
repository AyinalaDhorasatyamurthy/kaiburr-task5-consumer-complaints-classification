
# ğŸ§  Consumer Complaints Text Classification

**Project Goal:**  
Perform text classification on the [Consumer Complaint Database](https://catalog.data.gov/dataset/consumer-complaint-database) to automatically categorize complaints into four classes:

| Label | Category |
|:------|:----------|
| 0 | Credit reporting, repair, or other |
| 1 | Debt collection |
| 2 | Consumer loan |
| 3 | Mortgage |

---

## ğŸ“‚ Project Structure

```
consumer-complaints-classification/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ complaints.csv                # Raw dataset
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ logistic_model.pkl            # Saved Logistic Regression model
â”‚   â”œâ”€â”€ nb_model.pkl                  # Saved Naive Bayes model
â”‚   â””â”€â”€ svm_model.pkl                 # Saved SVM model
â”‚
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ confusion_matrix_logistic.png # Confusion matrix for Logistic Regression
â”‚   â”œâ”€â”€ confusion_matrix_nb.png       # Confusion matrix for Naive Bayes
â”‚   â””â”€â”€ confusion_matrix_svm.png      # Confusion matrix for SVM
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ consumer_complaints.ipynb     # Jupyter Notebook with full workflow
â”‚
â””â”€â”€ README.md                         # Project documentation
```

---

## ğŸš€ Steps Followed

### 1ï¸âƒ£ Exploratory Data Analysis (EDA)
- Checked dataset shape, column names, and null values  
- Visualized class distribution  
- Extracted only relevant text columns (`Issue`, `Narrative`, etc.)

### 2ï¸âƒ£ Text Pre-processing
- Lowercased all text  
- Removed punctuation, numbers, and stopwords  
- Tokenized and lemmatized text using **spaCy**

### 3ï¸âƒ£ Feature Engineering
- Used **TF-IDF Vectorization** with bigrams (`ngram_range=(1,2)`)  
- Limited features to top 10,000 for performance  

### 4ï¸âƒ£ Model Selection
Trained and compared three classification models:
- **Logistic Regression** â€” fast, strong baseline
- **Multinomial Naive Bayes** â€” simple and interpretable for text
- **Linear SVM (LinearSVC)** â€” powerful for sparse high-dimensional data

### 5ï¸âƒ£ Model Evaluation
Evaluated models using:
- Accuracy score  
- Classification report (Precision, Recall, F1-score)  
- Confusion matrices  

All metrics and confusion matrices are saved in the `/reports` folder.

---

## ğŸ“Š Model Performance (Example)

| Model | Accuracy | F1-score (macro) |
|:------|:----------|:----------------|
| Logistic Regression | 0.90 | 0.89 |
| Naive Bayes | 0.87 | 0.86 |
| SVM (LinearSVC) | 0.91 | 0.90 |

> *Your exact numbers may vary depending on preprocessing and data splits.*

---

## ğŸ’¾ Saved Models
All trained models are stored in `/models`:
```python
joblib.dump(log_model, '../models/logistic_model.pkl')
joblib.dump(nb_model, '../models/nb_model.pkl')
joblib.dump(svm_model, '../models/svm_model.pkl')
```

To reload a model later:
```python
import joblib
model = joblib.load('models/logistic_model.pkl')
```

---

## ğŸ“ˆ Visualizations
All confusion matrices are automatically saved to `/reports/`:
- `confusion_matrix_logistic.png`
- `confusion_matrix_nb.png`
- `confusion_matrix_svm.png`

---

## ğŸ§© Future Improvements
- Hyperparameter tuning using `GridSearchCV`
- Include more product categories
- Deploy as a web API using Flask or FastAPI
- Integrate model into Power BI for interactive dashboards

---

## âš™ï¸ Setup Instructions

### ğŸ”¹ Install Required Libraries
Run these commands in your terminal or Jupyter Notebook:
```bash
pip install pandas numpy scikit-learn matplotlib seaborn plotly spacy wordcloud joblib
python -m spacy download en_core_web_sm
```

### ğŸ”¹ Run the Notebook
Open `consumer_complaints.ipynb` in Jupyter and execute all cells.

---

## ğŸ Final Output
- Trained models: Logistic Regression, Naive Bayes, SVM  
- Evaluation reports and plots saved under `/reports/`  
- Ready-to-deploy `.pkl` models under `/models/`

---

## ğŸ‘¨â€ğŸ’» Author
**Kaiburr AI - Data Science Assessment**  
Developed as part of **Kaiburr Recruitment Data Science Task**  
Â© 2025 Kaiburr LLC. All Rights Reserved.
